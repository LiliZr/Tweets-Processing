{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435ae509-93a5-40d1-8231-e087e2ffe810",
   "metadata": {},
   "source": [
    "# Project - Apache Spark & Elastichsearch\n",
    "\n",
    "##### Students:\n",
    "* Lilia IZRI      (DS)\n",
    "* Yacine MOKHTARI (DS)\n",
    "* Alexandre COMBEAU (DS)\n",
    "\n",
    "##### Report\n",
    "[PENSER A METTRE UN LIEN ICI]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c595b944-090e-4992-975f-460ad48ab107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "\n",
    "# For ML\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.clustering import StreamingKMeans\n",
    "\n",
    "# From our util.py file\n",
    "from utils import sentiment, tweetToJSON\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f2660b-5c9e-4c43-80b7-aa6965c8ee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import elasticsearch\n",
    "elasticsearch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6281b-93c3-46c6-8186-8c009d7ba003",
   "metadata": {},
   "source": [
    "## I. Process & Analyze input data (tweets)\n",
    "### 1. Create our Dstream that receives data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94aac9-4d12-48e0-839c-ff4a7b05b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the SparkContext and StreamingContext with 10 second batch interval\n",
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 10)\n",
    "spark = SparkSession(sc)\n",
    "ssc.checkpoint(\"file:///tmp/spark\")    # Checkpoint for backups (useful for operations by window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f594469-a4e1-40c1-9a0e-a2115145c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate streaming text from a TCP (socket) source (Our tweets received)\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5567)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd75c44-b0a5-4720-89b3-2cc437cc8908",
   "metadata": {},
   "source": [
    "### 2. Process data and tag with sentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6f4d8-4ca3-4d65-a103-453e9d03bdd7",
   "metadata": {},
   "source": [
    "Here, we just took into account the polarity and choosed to ignore the subjectivity !  ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5adac6-fdf4-482b-9a36-c928c5f3d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the fields of the tweet received and we add tag the data with the sentiment of the tweet\n",
    "#   so the rdd below 'tweets' will be of the form (user, text, date, latitude, locations, hashtags, sentiment, tweet_id)\n",
    "def mapSplit(tweet):\n",
    "    \"\"\"\n",
    "    A function that takes a tweet  (the one we sent from the other iPython file),\n",
    "    splits it into its different fields and adds the sentiment field {-1, 0, 1}\n",
    "    \"\"\"\n",
    "    return (tweet[1],    tweet[2],  tweet[3],    tweet[4],    tweet[5],    tweet[6],   \"sentiment: \"+ str(sentiment(tweet[2][6:])), tweet[7])\n",
    "             #user        #text       #date      #latitude   #longitude    #Hashtags    #sentiment(= {-1,0,1})   #Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ae21a-eb75-428a-9171-eabeeaaa6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. Process the received tweets ( we will catch them the same way we sent them into the socket  :  \" ###field### field_name: ... ### ....\"\n",
    "tweets_split = socket_stream.map(lambda tweet: tweet.split(' ###:field:### '))\n",
    "tweets = tweets_split.map(mapSplit)\n",
    "\n",
    "#### 2. Tweets contains RDDs representented as tuples\n",
    "# tweets.pprint() # uncomment this line to see the tweets in the tuple format\n",
    "\n",
    "#### 3. json_list_per_stream is a list of tweets tuples converted  as a string following the JSON/Dict format\n",
    "json_list_per_stream = tweets.map(tweetToJSON)\n",
    "# json_list_per_stream.pprint() # uncomment this line to see the tweets in the JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4399e-2bd3-4420-919e-e701e68f09aa",
   "metadata": {},
   "source": [
    "Form of RDD in Tweets :\n",
    "``('user: userX', 'tweet: @userY blablablbabla', 'date: Thu May 05 00:16:06 +0000 2022', 'lat: 44.933143', 'lon: 7.540121', 'hashtags: #SaveTheWorld', 0, \"1237288393929\")``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5db5f2-05f7-4d1e-ae2f-fae5e351689e",
   "metadata": {},
   "source": [
    "### 3. ML : Cluster tweets according to sentiments and their location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fbab1f-bbda-4603-bcfd-5085aa4e0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a training set and test set \n",
    "training_data =  tweets.map(lambda tweet: Vectors.dense([float(tweet[6]), float(tweet[3][5:]), float(tweet[4][5:])]))\n",
    "testing_data  =  tweets.map(lambda tweet: LabeledPoint(float(tweet[6]), Vectors.dense([float(tweet[6]), float(tweet[3][5:]), float(tweet[4][5:])])))\n",
    "\n",
    "\n",
    "# We create a model with random clusters and specify the number of clusters to find\n",
    "k = 3\n",
    "dimension = 3\n",
    "weights = 0.0\n",
    "seed = 21\n",
    "\n",
    "# init\n",
    "model = StreamingKMeans(k=k, decayFactor=0.5).setRandomCenters(dimension, weights, seed)\n",
    "\n",
    "# Train the model\n",
    "model.trainOn(training_data)  \n",
    "\n",
    "# Predict\n",
    "result = model.predictOnValues(testing_data.map(lambda lp: (lp.label, lp.features)))\n",
    "# result.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10080f68-9cb3-4abd-80ef-a4949b2c8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the predictions of each tweet (the index of the cluster), and we create (indexCluster, 1) pairs\n",
    "predictions   = result.map(lambda x: (x[1], 1))\n",
    "\n",
    "# We reduce by key and window to get the number of elements assigned to each cluster\n",
    "size_clusters = predictions.reduceByKeyAndWindow(lambda x, y: x + y, lambda x, y: x - y, 30, 10)\n",
    "size_clusters.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e14e5-f5c3-43dc-88e1-2bc5075cb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.saveAsTextFiles(\"tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a36d86-7604-4449-993d-1fdfddc68790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start streaming and wait couple of minutes to get enought tweets\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babfc6e-27e1-4723-9ffb-19b519ef4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"helloooo\", json_list_per_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdb4b6-a11b-44ed-98e1-285bb7b0f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clusters coordinates: \" + str(model.latestModel().clusterCenters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5fe20-53fb-4439-870c-0c9e4bc3ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clusters coordinates: \" + str(model.latestModel().clusterCenters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588dea7-2fab-4168-945d-32fb387e2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## La bizarrement ça marche tout seul... mais quand c'est un stream ça plante\n",
    "\n",
    "\n",
    "# a = \"id: 234774849593\"\n",
    "\n",
    "# es.index(index=\"hello\",\n",
    "#                 id=int(a[4:]),\n",
    "#                 document={\"user\": \"lili\",\n",
    "#                           \"text\": \"22\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0fb6c-1366-419b-9362-b5c0a2146c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e48e8c-52d1-48e5-b728-d178ec3aeefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea27dfa-7129-4d4d-ac29-b08f98a354d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010aad0-5374-4967-b79b-f4d6907aaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d9dd2-c254-45a4-af10-862eb805b018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade92fdc-fd5e-467b-a739-51308a685f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15d00c-c67d-4689-b4fa-c6dfba4d342f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
