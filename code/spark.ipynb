{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435ae509-93a5-40d1-8231-e087e2ffe810",
   "metadata": {},
   "source": [
    "# Project - Apache Spark & Elastichsearch\n",
    "\n",
    "##### Students:\n",
    "* Lilia IZRI      (DS)\n",
    "* Yacine MOKHTARI (DS)\n",
    "* Alexandre COMBEAU (DS)\n",
    "\n",
    "##### Report\n",
    "[PENSER A METTRE UN LIEN ICI]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaff2493-0bf7-4427-b4b9-89ab6b3393eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.2.0-py3-none-any.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.6/378.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting elastic-transport<9,>=8\n",
      "  Downloading elastic_transport-8.1.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /opt/conda/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.8)\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.1.2 elasticsearch-8.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install textblob\n",
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c595b944-090e-4992-975f-460ad48ab107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For ML\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.clustering import StreamingKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c94aac9-4d12-48e0-839c-ff4a7b05b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the SparkContext and StreamingContext with 10 second batch interval\n",
    "sc = SparkContext()\n",
    "ssc = StreamingContext(sc, 10)\n",
    "spark = SparkSession(sc)\n",
    "ssc.checkpoint(\"file:///tmp/spark\")    # Checkpoint for backups (useful for operations by window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6281b-93c3-46c6-8186-8c009d7ba003",
   "metadata": {},
   "source": [
    "## I. Process & Analyze input data (tweets)\n",
    "### 1. Create our Dstream that receives data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f594469-a4e1-40c1-9a0e-a2115145c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate streaming text from a TCP (socket) source (Our tweets received)\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5553)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd75c44-b0a5-4720-89b3-2cc437cc8908",
   "metadata": {},
   "source": [
    "### 2. Process data and tag with sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbc4654-ee0a-4bed-a288-11c87e9e4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function that analysis text with textblob\n",
    "def sentiment(text):\n",
    "    \"\"\" Function that returns -1 if a tweet is more likely negative (polarity<0)\n",
    "                               0 if it's neutral  (polarity==0)\n",
    "                               1 if it's positive (polarity>0)\n",
    "    \"\"\"\n",
    "    polarity = TextBlob(text).polarity\n",
    "    return 1 if polarity > 0 else -1 if polarity < 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6f4d8-4ca3-4d65-a103-453e9d03bdd7",
   "metadata": {},
   "source": [
    "Here, we just took into account the polarity and choosed to ignore the subjectivity !  ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6ae21a-eb75-428a-9171-eabeeaaa6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the fields of the tweet received and we add tag the data with the sentiment of the tweet\n",
    "#   so the rdd below 'tweets' will be of the form (user, text, date, location, hashtags, sentiment)\n",
    "\n",
    "# def mapSplit(tweet):\n",
    "#     \"\"\"\n",
    "#     A function that takes a tweet  (the one we sent from the other iPython file),\n",
    "#     splits it into its different fields and adds the sentiment field {-1, 0, 1}\n",
    "#     \"\"\"\n",
    "#     tmp = tweet.split(' ###:field:### ')\n",
    "#     return (tweet[1], tweet[2], tweet[3], tweet[4], tweet[5], sentiment(tweet[2]))\n",
    "#              #user     #text    #date    #location  #hashtags  #sentiment(= {-1,0,1})\n",
    "    \n",
    "tweets = socket_stream.map(lambda tweet: tweet.split(' ###:field:### '))\\\n",
    "                      .map(lambda tweet: (tweet[1], tweet[2], tweet[3], tweet[4], tweet[5],   tweet[6],   sentiment(tweet[2][6:]), tweet[7]))\n",
    "                                           #user     #text    #date    #latitude  #longitude  #Hashtags  #sentiment(= {-1,0,1})   #Id\n",
    "\n",
    "# tweets = socket_stream.map(mapSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4399e-2bd3-4420-919e-e701e68f09aa",
   "metadata": {},
   "source": [
    "Form of RDD in Tweets :\n",
    "``('user: userX', 'tweet: @userY blablablbabla', 'date: Thu May 05 00:16:06 +0000 2022', 'lat: 44.933143', 'lon: 7.540121', 'hashtags: #SaveTheWorld', 0, \"1237288393929\")``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5db5f2-05f7-4d1e-ae2f-fae5e351689e",
   "metadata": {},
   "source": [
    "### 3. ML : Cluster tweets according to sentiments and their location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3fbab1f-bbda-4603-bcfd-5085aa4e0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a training set and test set \n",
    "training_data =  tweets.map(lambda tweet: Vectors.dense([float(tweet[6]), float(tweet[3][5:]), float(tweet[4][5:])]))\n",
    "testing_data  =  tweets.map(lambda tweet: LabeledPoint(float(tweet[6]), Vectors.dense([float(tweet[6]), float(tweet[3][5:]), float(tweet[4][5:])])))\n",
    "\n",
    "\n",
    "# We create a model with random clusters and specify the number of clusters to find\n",
    "k = 3\n",
    "dimension = 3\n",
    "weights = 0.0\n",
    "seed = 21\n",
    "\n",
    "# init\n",
    "model = StreamingKMeans(k=k, decayFactor=1.0).setRandomCenters(dimension, weights, seed)\n",
    "\n",
    "# Train the model\n",
    "model.trainOn(training_data)  \n",
    "\n",
    "# Predict\n",
    "result = model.predictOnValues(testing_data.map(lambda lp: (lp.label, lp.features)))\n",
    "result.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10080f68-9cb3-4abd-80ef-a4949b2c8cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the predictions of each tweet (the index of the cluster), and we create (indexCluster, 1) pairs\n",
    "predictions   = result.map(lambda x: (x[1], 1))\n",
    "\n",
    "# We reduce by key and window to get the number of elements assigned to each cluster\n",
    "size_clusters = predictions.reduceByKeyAndWindow(lambda x, y: x + y, lambda x, y: x - y, 30, 10)\n",
    "size_clusters.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649604f-70bc-4989-a00b-d7f2e269087d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## II. ElasticSearch Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a3ecc6-7e1b-4d5c-a145-96bc09ba1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "port = \"9200\"\n",
    "es = Elasticsearch(\"http://host.docker.internal:\" + port)  # The port you use when you launch elastic search on docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ba4e54-21c8-42eb-afdc-832711490f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Marche pass :((( dunno why\n",
    "\n",
    "\n",
    "\n",
    "# def saveES(tweet):\n",
    "#     es.index(index=\"sentiment_test1\",\n",
    "#         id=int(tweet[7][4:]),\n",
    "#         document={\"user\": tweet[0],\n",
    "#                   \"text\": tweet[1],\n",
    "#                   \"date\": tweet[2],\n",
    "#                   \"lat\":  tweet[3],\n",
    "#                   \"lon\":  tweet[4],\n",
    "#                   \"hashtags\": tweet[5],\n",
    "#                   \"sentiment\": tweet[6]})\n",
    "\n",
    "\n",
    "# tweets.foreachRDD(lambda rdd: saveES(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a088a3-3e22-4872-9d11-c839a9a54476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### A VOIR: pour utiliser ça il faut avoir un df :)))))) \n",
    "\n",
    "\n",
    "\n",
    "# query = df.writeStream \\\n",
    "# .outputMode(\"append\") \\\n",
    "# .queryName(\"writing_to_es\") \\\n",
    "# .format(\"org.elasticsearch.spark.sql\") \\\n",
    "# .option(\"checkpointLocation\", \"/tmp/\") \\\n",
    "# .option(\"es.resource\", \"index/type\") \\\n",
    "# .option(\"es.nodes\", \"http://host.docker.internal\") \\\n",
    "# .start()\n",
    "\n",
    "# query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a36d86-7604-4449-993d-1fdfddc68790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-05-05 02:59:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-05 02:59:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-05 02:59:50\n",
      "-------------------------------------------\n",
      "(0.0, 1)\n",
      "(0.0, 1)\n",
      "(0.0, 1)\n",
      "(0.0, 2)\n",
      "(0.0, 1)\n",
      "(0.0, 1)\n",
      "(0.0, 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-05-05 02:59:50\n",
      "-------------------------------------------\n",
      "(1, 6)\n",
      "(2, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start streaming and wait couple of minutes to get enought tweets\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3588dea7-2fab-4168-945d-32fb387e2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## La bizarrement ça marche tout seul... mais quand c'est un stream ça plante\n",
    "\n",
    "\n",
    "# a = \"id: 234774849593\"\n",
    "\n",
    "# es.index(index=\"hello\",\n",
    "#                 id=int(a[4:]),\n",
    "#                 document={\"user\": \"lili\",\n",
    "#                           \"text\": \"22\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0fb6c-1366-419b-9362-b5c0a2146c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e48e8c-52d1-48e5-b728-d178ec3aeefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea27dfa-7129-4d4d-ac29-b08f98a354d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010aad0-5374-4967-b79b-f4d6907aaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d9dd2-c254-45a4-af10-862eb805b018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade92fdc-fd5e-467b-a739-51308a685f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15d00c-c67d-4689-b4fa-c6dfba4d342f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
